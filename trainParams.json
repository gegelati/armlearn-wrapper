{
	// Choose between stopping in or reaching the objectives
	"reachingObjectives": true,
	// True if training validation is used for random starting pos and random target pos
	"doTrainingValidation": false,
	// If True, progressive mode is done by increasing motor position, instead it is the euclidian distance that increase
	"progressiveModeMotor": false,
	// If True, the target size will not be progressive but the range to reach will. If true, progressiveModeMotor is ignored
	"progressiveRangeTarget": true,
	// Use the progressive mode for choosing randomly the targets, is ignored if progressiveRangeTarget is true
	"progressiveModeTargets": true,
	// Initial maximum distance between the target and the starting position
	"maxLengthTargets": 200,
	// Allow to choose if the starting position are random of the BACKHOE one
	"doRandomStartingPosition": false,
	// Use the progressive mode for choosing randomly the starting position (no effect if doRandomStartingPosition is false)
	"progressiveModeStartingPos": false,
	// Initial maximum distance between the random starting position and the BACKHOE one
	"maxLengthStartingPos": 100,
	// Coefficient to upgrade the maxLengthStartingPos and MaxLengthTargets
	"coefficientUpgradeAdd": -20,
	// Coefficient to upgrade the maxLengthStartingPos and MaxLengthTargets
	"coefficientUpgradeMult": 0.8,
	// Number of iterations to cumulate to upgrade the maxLengthStartingPos and MaxLengthTargets
	"nbIterationsUpgrade": 2,
	// Distance in milimeters to reach to validate the target
	"rangeTarget" : 5,
	// Allow to start with a predifined TPG
	"startPreviousTPG": false,
	// Name of the predifined TPG (no effect if startPreviousTPG is false)
	"namePreviousTPG": "out_2078.dot",
	// True to activate a control over the deletion of trajectories
	"controlTrajectoriesDeletion": false,
	// Proportion of trajectories (pair startingPos-Target) reused at each training generation
	"propTrajectoriesReused": 0,
	// Penalty for moving a motor : the goal is to avoid to much speed unecessary
	"penaltySpeed" : 0.05,
	// Coefficient to multiply the reward with
	"coefRewardMultiplication" : 0.1,
	// true to load the validation trajectories
	"loadValidationTrajectories": false,
	// true to save the validation trajectories
	"saveValidationTrajectories": true,
	// Seed to init the algorithm (gegelati or SAC)
	"seed": 2,
	// Set interactive mode or not (usefull for calcul machine)
	"interactiveMode": true,
    // if true, selection for gegelati is based on score (sum of reward), else on distance
	"isScoreResult": false,
	// Value to penalize if an unavailable action is taken : reward = reward - penalty is isScoreResult is true, else score = score - penalty
	"penaltyMoveUnavailable": 1000,
	// Size in degree of a discrete action, and max size of a continuous action
	"sizeAction": 3,
	// if true, deactivate the training and only logs results
	"testing": false,
	// path to store the testing output
	"testPath": "../../result/Gegelati/outLogs/config_0_0/outLogs",

	// To use distance 2D instruction
	"useInstrDist2d": false,
	// To use distance 3D instruction
	"useInstrDist3d": false,
	// To use spherical coordonates instructions
	"useInstrSphericalCoord": false,
	// To use getPi instruction
	"useInstrPi": true,

	// If false, action change the motor position, if true action change the motor speed
	"actionSpeed": true,

	// True to allow coordonate/target bellow 0 on z axis and collision
	"realSimulation": true,

	// Number of training iteration (nbIterationsPerPolicyEvaluation will be only for validation/training validation)
	"nbIterationTraining": 3,

	// Set a limit of time to train (in seconds), if 0: no limit
	"timeMaxTraining": 15
}
